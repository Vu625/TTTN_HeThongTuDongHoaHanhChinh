def run_ocr_and_validate():
    #(t√≠ch h·ª£p Tesseract, PIL, RegEx).
    pass
import numpy as np
import cv2
import pytesseract
from PIL import Image
from pathlib import Path
import io
import streamlit as st
import os
import re
from  models.ocr.tessdata import config
# from models.ocr.tessdata import config
# tesseract_path = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
# if tesseract_path:
#     pytesseract.tesseract_cmd = tesseract_path

UPLOAD_DIR = Path("data/db/uploads")
UPLOAD_DIR.mkdir(exist_ok=True)


def save_uploaded_file(uploaded_file):
    file_path = UPLOAD_DIR / uploaded_file.name
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return str(file_path)

# def extract_text(file_path):
#     try:
#         img = Image.open(file_path)
#         text = pytesseract.image_to_string(img, lang="vie")
#         return text.strip()
#     except Exception as e:
#         st.error(f"L·ªói OCR: {e}")
#         return ""

def preprocess_image(image_path):
    """
    Ti·ªÅn x·ª≠ l√Ω h√¨nh ·∫£nh: Chuy·ªÉn sang thang ƒë·ªô x√°m, l√†m m·ªù v√† ph√¢n ng∆∞·ª°ng th√≠ch nghi.
    M·ª•c ƒë√≠ch: Gi√∫p Tesseract d·ªÖ d√†ng ph√¢n bi·ªát ch·ªØ c√°i v√† n·ªÅn.
    """
    try:
        # 1. T·∫£i ·∫£nh b·∫±ng OpenCV (d·ªÖ x·ª≠ l√Ω h∆°n PIL cho c√°c b∆∞·ªõc n√¢ng cao)
        img = cv2.imread(image_path)
        if img is None:
            raise FileNotFoundError("Kh√¥ng th·ªÉ ƒë·ªçc file ·∫£nh.")

        # 2. Chuy·ªÉn ·∫£nh sang thang ƒë·ªô x√°m (Grayscale)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # 3. L√†m m·ªù Gaussian: Gi√∫p lo·∫°i b·ªè nhi·ªÖu v√† l√†m m·ªãn c√°c chi ti·∫øt nh·ªè
        # gray = cv2.GaussianBlur(gray, (5, 5), 0)

        # 4. Ph√¢n ng∆∞·ª°ng th√≠ch nghi (Adaptive Thresholding):
        # Bi·∫øn ƒë·ªïi ·∫£nh th√†nh tr·∫Øng ƒëen d·ª±a tr√™n c∆∞·ªùng ƒë·ªô s√°ng c·ª•c b·ªô.
        # R·∫•t hi·ªáu qu·∫£ v·ªõi ·∫£nh c√≥ ƒëi·ªÅu ki·ªán √°nh s√°ng kh√¥ng ƒë·ªÅu (nh∆∞ ·∫£nh ch·ª•p).
        thresh = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )

        # Th·ª≠ nghi·ªám th√™m: N·∫øu font ch·ªØ nh·ªè ho·∫∑c b·ªã m·ªù, c√≥ th·ªÉ c·∫ßn Dilation/Erosion
        # kernel = np.ones((1, 1), np.uint8)
        # thresh = cv2.erode(thresh, kernel, iterations=1)
        # thresh = cv2.dilate(thresh, kernel, iterations=1)

        # Chuy·ªÉn ƒë·ªïi ·∫£nh OpenCV (numpy array) sang ƒë·ªãnh d·∫°ng PIL Image
        # ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi pytesseract.image_to_string
        return Image.fromarray(gray)

    except Exception as e:
        st.error(f"L·ªói ti·ªÅn x·ª≠ l√Ω ·∫£nh: {e}")
        return None


def extract_text(file_path):
    """
    Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file ·∫£nh sau khi ƒë√£ ti·ªÅn x·ª≠ l√Ω.
    """
    # 1. Ti·ªÅn x·ª≠ l√Ω ·∫£nh
    processed_img = preprocess_image(file_path)

    if processed_img is None:
        return ""

    try:
        # 2. G·ªçi OCR tr√™n ·∫£nh ƒë√£ x·ª≠ l√Ω
        # lang="vie" ch·ªâ ƒë·ªãnh g√≥i ng√¥n ng·ªØ Ti·∫øng Vi·ªát
        # --psm 6: Gi·∫£ ƒë·ªãnh m·ªôt kh·ªëi vƒÉn b·∫£n duy nh·∫•t (Th√≠ch h·ª£p cho gi·∫•y t·ªù)
        custom_config = r'--psm 6'

        text = pytesseract.image_to_string(processed_img, lang="vie", config=custom_config)

        return text.strip()

    except Exception as e:
        # Hi·ªÉn th·ªã l·ªói cu·ªëi c√πng (c√≥ th·ªÉ l√† l·ªói ng√¥n ng·ªØ, ho·∫∑c file kh√¥ng ƒë·ªçc ƒë∆∞·ª£c)
        st.error(f"L·ªói OCR: Kh√¥ng th·ªÉ tr√≠ch xu·∫•t vƒÉn b·∫£n. Chi ti·∫øt: {e}")
        return ""




# tesseract_path = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
# if tesseract_path:
#     pytesseract.tesseract_cmd = tesseract_path



# 2. Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn file ·∫£nh CCCD b·∫°n mu·ªën OCR:
#    (Thay th·∫ø b·∫±ng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ho·∫∑c t∆∞∆°ng ƒë·ªëi ƒë·∫øn ·∫£nh c·ªßa b·∫°n)
# img_path = "Cancuoc_vu.png"
# =========================================================================

def ocr_cccd(image_path):
    # Ki·ªÉm tra file ·∫£nh c√≥ t·ªìn t·∫°i kh√¥ng
    if not os.path.exists(image_path):
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file ·∫£nh t·∫°i ƒë∆∞·ªùng d·∫´n: {image_path}")
        return {"data": {}, "has_title": False, "is_cccd_document": False}

    # B∆∞·ªõc 1 & 2: ƒê·ªçc ·∫£nh (thay th·∫ø b∆∞·ªõc upload c·ªßa Colab)
    try:
        image = Image.open(image_path)
    except Exception as e:
        print(f"‚ùå L·ªói khi m·ªü ·∫£nh: {e}")
        return {"data": {}, "has_title": False, "is_cccd_document": False}

    # OCR 1: Grayscale ƒë·ªÉ l·∫•y ch√≠nh x√°c "CƒÇN C∆Ø·ªöC C√îNG D√ÇN"
    img_gray = image.convert("L")

    # ‚ö†Ô∏è L∆∞u √Ω: Trong PyCharm, kh√¥ng c·∫ßn ph·∫£i l∆∞u file t·∫°m trong /content/
    #           nh∆∞ Colab, nh∆∞ng ta v·∫´n gi·ªØ l·∫°i ƒë·ªÉ d·ªÖ debug
    # img_gray.save("img_gray_temp.png")

    text_gray = pytesseract.image_to_string(img_gray, lang='vie')
    print("OCR Grayscale (cho title):")
    print(text_gray)

    # OCR 2: ·∫¢nh g·ªëc ƒë·ªÉ l·∫•y th√¥ng tin chi ti·∫øt ch√≠nh x√°c
    text_original = pytesseract.image_to_string(image, lang='vie')
    print("\nOCR Original (cho data):")
    print(text_original)

    # B∆∞·ªõc 3: Ki·ªÉm tra title t·ª´ OCR grayscale
    target_title = "CƒÇN C∆Ø·ªöC C√îNG D√ÇN"
    has_title = target_title.lower() in text_gray.lower()
    print(f"\nC√≥ 'CƒÇN C∆Ø·ªöC C√îNG D√ÇN': {'‚úÖ ƒê√∫ng' if has_title else '‚ùå Sai'}")

    # --- B∆Ø·ªöC 4: T√ÅCH TH√îNG TIN B·∫∞NG REGEX (GI·ªÆ NGUY√äN CODE C·ª¶A B·∫†N) ---
    data = {}

    # S·ªë CCCD: T√¨m chu·ªói g·∫ßn "s·ªë" ho·∫∑c 12 ch·ªØ s·ªë
    m = re.search(r'(?:s·ªë|s√≥|x√≥|so)[/:\s]*([^\s]*\d{12}[^\s]*)', text_original, re.IGNORECASE)
    if not m:
        m = re.search(r'(\d{12})', text_original)
    if m:
        digits = re.sub(r'\D', '', m.group(1))
        if len(digits) >= 12:
            data['So_CCCD'] = digits[:12]

    # H·ªç v√† t√™n (m·ªõi) ‚Äî t√¨m n·ªôi dung tr√™n c√πng d√≤ng ho·∫∑c tr√™n d√≤ng ti·∫øp theo n·∫øu c√πng d√≤ng r·ªóng/kh√¥ng ph·∫£i t√™n
    lines = text_original.splitlines()
    name_found = None
    for i, line in enumerate(lines):
        if re.search(r'H·ªç\s+v√†\s+t√™n', line, re.IGNORECASE):
            # ki·ªÉm tra c√πng d√≤ng
            after = re.sub(r'.*H·ªç\s+v√†\s+t√™n[^\w]*(.*)', r'\1', line, flags=re.IGNORECASE).strip()
            if after and not re.search(r'full\s*name', after, re.IGNORECASE):
                name_found = re.sub(r'^(Full\s*name[:\s\-]*)', '', after, flags=re.IGNORECASE).strip()
            else:
                # th·ª≠ d√≤ng ti·∫øp theo (v√† ti·∫øp theo n·∫øu g·∫∑p d√≤ng r·ªóng)
                j = i + 1
                while j < len(lines) and not lines[j].strip():
                    j += 1
                if j < len(lines):
                    candidate = lines[j].strip()
                    # lo·∫°i b·ªè n·∫øu candidate v·∫´n l√† label ti·∫øng Anh
                    if not re.search(r'full\s*name', candidate, re.IGNORECASE):
                        name_found = candidate
            break

    if name_found:
        data['Ho_va_ten'] = name_found


    # Ng√†y sinh
    # Ng√†y sinh (ph∆∞∆°ng √°n A m·ªü r·ªông)
    m = re.search(r'Ng√†y\s*sinh[^\n\r]*?(\d{1,2}[/\\\-]\d{1,2}[/\\\-]\d{2,4})', text_original, re.IGNORECASE)
    birth_candidate = None
    if m:
        birth_candidate = m.group(1).strip()
    else:
        # n·∫øu kh√¥ng c√≥ trong c√πng d√≤ng, th·ª≠ l·∫•y d√≤ng k·∫ø ti·∫øp
        pos = re.search(r'Ng√†y\s*sinh', text_original, re.IGNORECASE)
        if pos:
            rest = text_original[pos.end():].lstrip('\r\n')
            next_line = None
            for line in rest.splitlines():
                if line.strip():
                    next_line = line.strip()
                    break
            if next_line:
                m2 = re.search(r'(\d{1,2}[/\\\-]\d{1,2}[/\\\-]\d{2,4})', next_line)
                if m2:
                    birth_candidate = m2.group(1).strip()
    if birth_candidate:
        data['Ngay_sinh'] = birth_candidate

    # üß© Gi·ªõi t√≠nh (m·ªõi th√™m)
    gender_match = re.search(r'Gi·ªõi\s*t√≠nh[^\n\r:]*[:\-]?\s*([A-Za-z√Ä-·ª∏√†-·ªπ]+)', text_original, re.IGNORECASE)
    gender_candidate = None
    if gender_match:
        gender_candidate = gender_match.group(1).strip()
    else:
        # n·∫øu kh√¥ng c√≥ trong c√πng d√≤ng, t√¨m d√≤ng k·∫ø ti·∫øp
        pos = re.search(r'Gi·ªõi\s*t√≠nh', text_original, re.IGNORECASE)
        if pos:
            rest = text_original[pos.end():].lstrip('\r\n')
            for line in rest.splitlines():
                if line.strip():
                    gender_candidate = line.strip().split()[0]
                    break
    if gender_candidate:
        # chu·∫©n h√≥a k·∫øt qu·∫£
        gender_candidate = gender_candidate.replace("qu√©c", "").replace("t·ªãch", "").strip(" .:-")
        if re.search(r'nam', gender_candidate, re.IGNORECASE):
            data['Gioi_tinh'] = "Nam"
        elif re.search(r'n·ªØ|nu|fem', gender_candidate, re.IGNORECASE):
            data['Gioi_tinh'] = "N·ªØ"
        else:
            data['Gioi_tinh'] = gender_candidate

    # Qu√™ qu√°n
    # ‚úÖ Qu√™ qu√°n (ƒë√£ ch·ªânh ƒë·ªÉ l·∫•y d√≤ng k·∫ø ti·∫øp n·∫øu c·∫ßn)
    lines = text_original.splitlines()
    for i, line in enumerate(lines):
        if re.search(r'Qu√™\s+qu√°n', line, re.IGNORECASE):
            after = re.sub(r'.*Qu√™\s+qu√°n[^\w]*(.*)', r'\1', line, flags=re.IGNORECASE).strip()
            if after and not re.search(r'Place\s*of\s*origin', after, re.IGNORECASE):
                data['Que_quan'] = after
            else:
                j = i + 1
                while j < len(lines) and not lines[j].strip():
                    j += 1
                if j < len(lines):
                    candidate = lines[j].strip()
                    if not re.search(r'Place\s*of\s*origin', candidate, re.IGNORECASE):
                        data['Que_quan'] = candidate
            break


    # N∆°i th∆∞·ªùng tr√∫
    # N∆°i th∆∞·ªùng tr√∫ ‚Äî ∆∞u ti√™n t·ª´ ·∫£nh g·ªëc, fallback sang ·∫£nh grayscale n·∫øu c·∫ßn
    def extract_residence(text):
        lines = text.splitlines()
        for i, line in enumerate(lines):
            if re.search(r'N∆°i\s+th∆∞·ªùng\s+tr√∫', line, re.IGNORECASE):
                after = re.sub(r'.*N∆°i\s+th∆∞·ªùng\s+tr√∫[^\w]*(.*)', r'\1', line, flags=re.IGNORECASE).strip()
                if after and not re.search(r'Place\s*of\s*residence', after, re.IGNORECASE):
                    return after
                else:
                    j = i + 1
                    while j < len(lines) and not lines[j].strip():
                        j += 1
                    if j < len(lines):
                        candidate = lines[j].strip()
                        if not re.search(r'Place\s*of\s*residence', candidate, re.IGNORECASE):
                            return candidate
        return None

    # Th·ª≠ l·∫•y t·ª´ ·∫£nh g·ªëc
    residence = extract_residence(text_original)

    # N·∫øu kh√¥ng c√≥ ho·∫∑c b·ªã l·ªói, th·ª≠ l·∫•y t·ª´ ·∫£nh grayscale
    if not residence or len(residence) < 10:
        residence_gray = extract_residence(text_gray)
        if residence_gray and len(residence_gray) > len(residence or ''):
            residence = residence_gray

    if residence:
        data['Noi_thuong_tru'] = residence

    # --- K·∫æT TH√öC B∆Ø·ªöC 4 ---

    # B∆∞·ªõc 5: Ki·ªÉm tra h·ª£p l·ªá
    id_num = data.get('So_CCCD', '') # S·ª≠a kh√≥a t·ª´ 'S·ªë CCCD' th√†nh 'So_CCCD' cho nh·∫•t qu√°n
    text_upper = (text_original + text_gray).upper()

    # T·ª´ kh√≥a nh·∫≠n d·∫°ng CCCD
    required_keywords = ["CCCD", "CƒÇN C∆Ø·ªöC C√îNG D√ÇN", "CIFIZEN LIDENTITY", "CITIZEN IDENTITY"]
    is_cccd_document = has_title or any(keyword in text_upper for keyword in required_keywords)

    # T·ª´ kh√≥a lo·∫°i tr·ª´
    forbidden_keywords = [
        "GI·∫§Y PH√âP L√ÅI XE", "B·∫∞NG L√ÅI XE", "DRIVER", "GTVT", "B·ªò GTVT",
        "PASSPORT", "H·ªò CHI·∫æU", "GI·∫§Y PH√âP", "B·∫∞NG", "XE M√ÅY", "√î T√î"
    ]
    is_forbidden_document = any(keyword in text_upper for keyword in forbidden_keywords)

    # H·ª£p l·ªá: C√≥ title V√Ä s·ªë 12 ch·ªØ s·ªë V√Ä kh√¥ng forbidden
    if id_num and len(id_num) == 12 and has_title and not is_forbidden_document:
        print("\n‚úÖ Th√¥ng tin cƒÉn c∆∞·ªõc c√¥ng d√¢n h·ª£p l·ªá:")
        for k, v in data.items():
            print(f"{k}: {v}")
    elif id_num and len(id_num) == 12 and not has_title:
        print("\n‚ùå ·∫¢nh c√≥ 12 ch·ªØ s·ªë, nh∆∞ng KH√îNG c√≥ 'CƒÇN C∆Ø·ªöC C√îNG D√ÇN' ‚Üí Kh√¥ng ph·∫£i cƒÉn c∆∞·ªõc!")
    elif not id_num:
        print("\n‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y s·ªë CCCD 12 ch·ªØ s·ªë.")
    elif is_forbidden_document:
        print("\n‚ùå L·ªói: C√≥ v·∫ª l√† t√†i li·ªáu KH√îNG ph·∫£i CCCD (B·∫±ng l√°i/Passport...)")
    else:
        print("\n‚ùå L·ªói: Kh√¥ng th·ªÉ x√°c nh·∫≠n l√† CƒÉn c∆∞·ªõc c√¥ng d√¢n.")

    # Tr·∫£ v·ªÅ to√†n b·ªô d·ªØ li·ªáu ƒë·ªÉ c√≥ th·ªÉ x·ª≠ l√Ω ti·∫øp
    if 'So_CCCD' not in data:
        data['So_CCCD']=""
    if 'Ho_va_ten' not in data:
        data['Ho_va_ten']=""
    if 'Gioi_tinh' not in data:
        data['Gioi_tinh']=""
    if 'Que_quan' not in data:
        data['Que_quan']=""
    if 'Noi_thuong_tru' not in data:
        data['Noi_thuong_tru']=""
    data_ocr = [
        {'name':"So_CCCD",'label':"S·ªë CƒÉn C∆∞·ªõc C√¥ng D√¢n",'text': data['So_CCCD']},
        {'name': "Ho_va_ten", 'label': "H·ªç V√† T√™n", 'text': data['Ho_va_ten']},
        {'name': "Gioi_tinh", 'label': "Gi·ªõi T√≠nh", 'text': data['Gioi_tinh']},
        {'name': "Que_quan", 'label': "Qu√™ Qu√°n", 'text': data['Que_quan']},
        {'name': "Noi_thuong_tru", 'label': "N∆°i Th∆∞·ªùng Tr√∫", 'text': data['Noi_thuong_tru']},
         ]
    return {
        "data": data_ocr,
        "has_title": has_title,

    }

# a = ocr_cccd("data\\db\\uploads\\GPLX_mattruoc.jpg")
#
# print(a)

